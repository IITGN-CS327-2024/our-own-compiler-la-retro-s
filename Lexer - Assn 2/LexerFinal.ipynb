{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1U1xLm_HNRC4",
        "outputId": "39863aa4-f54f-4b89-832f-1be00bc95c7c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Keyword', 'int'), ('Whitespace', ' '), ('Keyword', 'start'), ('Paranthesis', '('), ('Paranthesis', ')'), ('Paranthesis', '{'), ('Whitespace', '\\n'), ('Keyword', 'bool'), ('Whitespace', ' '), ('Identifier', 'a'), ('Whitespace', ' '), ('BinaryOperator', '='), ('Whitespace', ' '), ('Identifier', 'True'), ('Whitespace', ' '), ('UnaryOperator', '&'), ('UnaryOperator', '&'), ('Whitespace', ' '), ('Identifier', 'False'), ('EndOfStatement', ';'), ('Whitespace', '\\n'), ('Keyword', 'display'), ('Paranthesis', '('), ('Identifier', 'a'), ('Paranthesis', ')'), ('EndOfStatement', ';'), ('Whitespace', '\\n'), ('Keyword', 'word'), ('Whitespace', ' '), ('Identifier', 'str'), ('Whitespace', ' '), ('BinaryOperator', '='), ('Whitespace', ' '), ('Constant', '“Kulant”'), ('EndOfStatement', ';'), ('Whitespace', '\\n'), ('Identifier', 'Word'), ('Whitespace', ' '), ('Identifier', 'str1'), ('Whitespace', ' '), ('BinaryOperator', '='), ('Whitespace', ' '), ('Constant', '“Pro”'), ('EndOfStatement', ';'), ('Whitespace', '\\n'), ('Identifier', 'str'), ('Whitespace', ' '), ('BinaryOperator', '='), ('Whitespace', ' '), ('Identifier', 'str'), ('BinaryOperator', '+'), ('Identifier', 'str1'), ('Whitespace', '\\xa0\\n'), ('Keyword', 'display'), ('Paranthesis', '('), ('Identifier', 'str'), ('Paranthesis', ')'), ('Whitespace', '\\n'), ('Keyword', 'word'), ('Whitespace', ' '), ('Identifier', 'x'), ('Whitespace', ' '), ('BinaryOperator', '='), ('Whitespace', ' '), ('Constant', '“abhaykumar”'), ('EndOfStatement', ';'), ('Whitespace', '\\n'), ('Keyword', 'display'), ('Paranthesis', '('), ('Identifier', 'x'), ('Paranthesis', '['), ('Constant', '6]'), ('Paranthesis', ')'), ('EndOfStatement', ';'), ('Whitespace', '\\n'), ('Keyword', 'return'), ('Whitespace', ' '), ('Constant', '0'), ('EndOfStatement', ';'), ('Whitespace', '\\n'), ('Paranthesis', '}')]\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "class SimpleLangLexer:\n",
        "    def __init__(self):\n",
        "        self.token_patterns = [\n",
        "            ('Keyword', r'\\b(int|word|bigint|char|dotie|bool|list|constant|tuple|if|otif|otw|for|while|get_out|go_on|return|void|try|catch|finally|display|input|start)\\b'),\n",
        "            ('Identifier', r'\\b[a-zA-Z_][a-zA-Z0-9_]*\\b'),\n",
        "            ('UnaryOperator', r'-|!|&|sizeof\\(\\)'),\n",
        "            ('BinaryOperator', r'==|!=|<=|>=|\\|\\||&&|[+\\-*/=](?!=)'),\n",
        "            ('LogicalLiteral', r'True|False'),\n",
        "            ('StringLiteral', r'\"([^\"]*)\"'),\n",
        "            ('Whitespace', r'\\s+'),\n",
        "            ('Paranthesis', r'[()\\{\\}\\[\\]]'),\n",
        "            ('Quotation', r'\"'),\n",
        "            ('Constant', r'[^\"{}\\s();]+'),\n",
        "            ('EndOfStatement', r';')\n",
        "        ]\n",
        "\n",
        "    def tokenize(self, source_code):\n",
        "        tokens = []\n",
        "        position = 0\n",
        "\n",
        "        while position < len(source_code):\n",
        "            match = None\n",
        "\n",
        "            for token_type, pattern in self.token_patterns:\n",
        "                regex = re.compile(pattern)\n",
        "                match = regex.match(source_code, position)\n",
        "\n",
        "                if match:\n",
        "                    if token_type == 'StringLiteral':\n",
        "                        tokens.append(('Quotation', '\"'))\n",
        "                        tokens.append(('StringLiteral', match.group(1)))\n",
        "                        tokens.append(('Quotation', '\"'))\n",
        "                    else:\n",
        "                        tokens.append((token_type, match.group(0)))\n",
        "                    position = match.end()\n",
        "                    break\n",
        "\n",
        "            if not match:\n",
        "                raise Exception(f\"Unexpected character at position {position}: {source_code[position]}\")\n",
        "\n",
        "        return tokens\n",
        "\n",
        "\n",
        "def main():\n",
        "    filename = \"test4.kul\"\n",
        "    with open(filename, 'r') as file:\n",
        "        source_code = file.read()\n",
        "\n",
        "    lexer = SimpleLangLexer()\n",
        "    tokens = lexer.tokenize(source_code)\n",
        "\n",
        "    print(tokens)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}